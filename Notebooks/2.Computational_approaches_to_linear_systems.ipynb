{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "format:\n",
    "  html:\n",
    "    embed-resources: true\n",
    "    fig-width: 9\n",
    "    fig-height: 6\n",
    "jupyter: python3\n",
    "code-fold: true\n",
    "code-overflow: wrap\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "   import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy and SciPy linear algebra solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy provides basic linear algebra routines through $\\texttt{numpy.linalg}$. These functions internally use **LAPACK** and **BLAS** for efficiency.\n",
    "\n",
    "\n",
    "1. **Solving a system of linear equations**  \n",
    "   Given the system:\n",
    "\n",
    "   $$ Ax = b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8 1.3]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[3, 2], [1, 4]])\n",
    "B = np.array([5, 6])\n",
    "x = np.linalg.solve(A, B)  # Solves Ax = B\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses an efficient algorithm (Gaussian elimination with partial pivoting) to find x. Refer to [this link](https://numpy.org/doc/2.2/reference/generated/numpy.linalg.solve.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Computing the inverse of a matrix**\n",
    "  $$ A^{-1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8 1.3]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "   A_inv = np.linalg.inv(A) # Inverse of A\n",
    "   x = np.dot(A_inv, B) # Solves Ax = B\n",
    "   print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the matrix must non-singular $(\\det(A) \\neq 0)$  for this to work. Click the [link](https://numpy.org/doc/2.2/reference/generated/numpy.linalg.inv.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Computing the determinant**<br>\n",
    "The determinant of a square matrix A is a scalar value that provides important information about the matrix. It is denoted as:\n",
    "   $$ \\det(A) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8 1.3]\n"
     ]
    }
   ],
   "source": [
    "det_A = np.linalg.det(A) # Determinant of A\n",
    "# Check if the determinant is zero\n",
    "if det_A == 0:\n",
    "    print(\"The system has no unique solution (determinant is zero).\")\n",
    "else:\n",
    "    x = np.linalg.solve(A, B) # Solves Ax = B\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nonzero determinant means A is invertible, while det(A) = 0 means A is singular (not invertible)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Eigenvalues and Eigenvectors**\n",
    "\n",
    "For a square matrix \\( $A$ \\), the eigenvalues (\\( $\\lambda$ \\)) and corresponding eigenvectors (\\( $v$ \\)) satisfy the equation:\n",
    "\n",
    "$$\n",
    "A \\cdot v = \\lambda \\cdot v\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- \\( $\\lambda$ \\) (lambda) is a **scalar** (eigenvalue),\n",
    "- \\( $v$ \\) is a **nonzero vector** (eigenvector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution X: [0.8 1.3]\n"
     ]
    }
   ],
   "source": [
    "# Eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors  = np.linalg.eig(A) # compute eigenvalues and eigenvectors\n",
    "\n",
    "# Diagonal matrix of eigenvalues\n",
    "D = np.diag(eigenvalues)\n",
    "\n",
    "# Compute P inverse\n",
    "P_inv = np.linalg.inv(eigenvectors)\n",
    "\n",
    "# Transform B into the eigenbasis\n",
    "B_prime = P_inv @ B\n",
    "\n",
    "# Solve for Y in DY = B'\n",
    "Y = np.linalg.solve(D, B_prime)\n",
    "\n",
    "# Compute the final solution X = P Y\n",
    "X = eigenvectors @ Y\n",
    "\n",
    "# Print the result\n",
    "print(\"Solution X:\", X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELI5: Eigenvectors \"point\" in the same direction as most of your data, and eigenvalues tell you how strongly your data points that direction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Singular Value Decomposition (SVD)**\n",
    "\n",
    "Singular Value Decomposition (SVD) is a method to break down a complex matrix into simpler components. It is similar to taking a blurry image and separating it into clear building blocks.\n",
    "\n",
    "### SVD Formula\n",
    "For any matrix \\( $A$ \\), SVD expresses it as:\n",
    "\n",
    "$$ A = U \\Sigma V^T $$\n",
    "\n",
    "Where:\n",
    "- **\\( $U$ \\)** (Left singular vectors) → Contains important patterns from the original data.\n",
    "- **\\( $\\Sigma$ \\)** (Singular values) → A diagonal matrix with values indicating the importance of each pattern.\n",
    "- **\\( $V^{T}$ \\)** (Right singular vectors) → Contains another set of patterns that, when combined with \\( $\\Sigma$ \\), recreate the original data.\n",
    "\n",
    "Analogy:<br>\n",
    "Imagine you have a large playlist of songs. SVD breaks it down into:\n",
    "- **\\( $U$\\)** → The general themes of music (e.g., rock, jazz, pop).\n",
    "- **\\( $\\Sigma$ \\)** → How strongly each theme appears in the playlist.\n",
    "- **\\( $V^{T}$ \\)** → The details of each song, arranged by themes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution X: [0.8 1.3]\n"
     ]
    }
   ],
   "source": [
    "# Compute Singular Value Decomposition (SVD)\n",
    "U, S, V = np.linalg.svd(A)\n",
    "\n",
    "# Convert S into a diagonal matrix\n",
    "S_diag = np.diag(S)\n",
    "\n",
    "# Compute the pseudo-inverse of S\n",
    "S_inv = np.linalg.inv(S_diag)\n",
    "\n",
    "# Compute the pseudo-inverse of A using SVD\n",
    "A_pinv = V.T @ S_inv @ U.T # @ means matrix multiplication and .T means transpose\n",
    "\n",
    "# Solve for X using the pseudo-inverse\n",
    "X = A_pinv @ B\n",
    "\n",
    "# Print the result\n",
    "print(\"Solution X:\", X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\\section{SciPy Linear Algebra (\\texttt{scipy.linalg})}\n",
    "\n",
    "SciPy extends NumPy's linear algebra capabilities with additional **matrix decompositions, advanced solvers, and performance optimizations**.\n",
    "\n",
    "\\subsection{Key Advantages of SciPy over NumPy}\n",
    "- Uses **LAPACK** and **ATLAS**, but with extra options for optimization.\n",
    "- Supports sparse matrices via \\texttt{scipy.sparse.linalg}.\n",
    "- Includes additional decomposition methods.\n",
    "\n",
    "\\subsection{Common SciPy Linear Algebra Solvers}\n",
    "\n",
    "1. **Solving a linear system (\\texttt{scipy.linalg.solve})**  \n",
    "   Same as \\texttt{numpy.linalg.solve} but often faster and more stable.\n",
    "\n",
    "   \\begin{verbatim}\n",
    "   from scipy.linalg import solve\n",
    "\n",
    "   x = solve(A, b)  # More efficient than np.linalg.solve for large matrices\n",
    "   print(x)\n",
    "   \\end{verbatim}\n",
    "\n",
    "2. **LU Decomposition**  \n",
    "\n",
    "   $$ PA = LU $$\n",
    "\n",
    "   \\begin{verbatim}\n",
    "   from scipy.linalg import lu\n",
    "\n",
    "   P, L, U = lu(A)  # P: Permutation, L: Lower triangular, U: Upper triangular\n",
    "   \\end{verbatim}\n",
    "\n",
    "3. **QR Decomposition**  \n",
    "\n",
    "   $$ A = QR $$\n",
    "\n",
    "   \\begin{verbatim}\n",
    "   from scipy.linalg import qr\n",
    "\n",
    "   Q, R = qr(A)\n",
    "   \\end{verbatim}\n",
    "\n",
    "4. **Cholesky Decomposition (for positive definite matrices)**  \n",
    "\n",
    "   $$ A = LL^T $$\n",
    "\n",
    "   \\begin{verbatim}\n",
    "   from scipy.linalg import cholesky\n",
    "\n",
    "   L = cholesky(A, lower=True)\n",
    "   \\end{verbatim}\n",
    "\n",
    "5. **Eigenvalue Problems (\\texttt{scipy.linalg.eig})**\n",
    "\n",
    "   \\begin{verbatim}\n",
    "   from scipy.linalg import eig\n",
    "\n",
    "   eigvals, eigvecs = eig(A)\n",
    "   \\end{verbatim}\n",
    "\n",
    "6. **Singular Value Decomposition (SVD)**  \n",
    "\n",
    "   $$ A = U S V^T $$\n",
    "\n",
    "   \\begin{verbatim}\n",
    "   from scipy.linalg import svd\n",
    "\n",
    "   U, S, V = svd(A)\n",
    "   \\end{verbatim}\n",
    "\n",
    "---\n",
    "\n",
    "\\section{Sparse Linear Algebra (\\texttt{scipy.sparse.linalg})}\n",
    "\n",
    "For large, sparse matrices, SciPy provides \\texttt{scipy.sparse.linalg}, which is optimized for efficiency.\n",
    "\n",
    "1. **Solving a sparse linear system**  \n",
    "\n",
    "   $$ Ax = b $$\n",
    "\n",
    "   \\begin{verbatim}\n",
    "   from scipy.sparse import csc_matrix\n",
    "   from scipy.sparse.linalg import spsolve\n",
    "\n",
    "   A_sparse = csc_matrix(A)  # Convert A to sparse format\n",
    "   x = spsolve(A_sparse, b)\n",
    "   \\end{verbatim}\n",
    "\n",
    "2. **Iterative solvers (Conjugate Gradient, GMRES)**  \n",
    "\n",
    "   \\begin{verbatim}\n",
    "   from scipy.sparse.linalg import cg  # Conjugate Gradient\n",
    "\n",
    "   x, info = cg(A_sparse, b)\n",
    "   \\end{verbatim}\n",
    "\n",
    "---\n",
    "\n",
    "\\section{When to Use NumPy vs. SciPy?}\n",
    "\n",
    "\\begin{center}\n",
    "\\begin{tabular}{|c|c|c|}\n",
    "\\hline\n",
    "\\textbf{Feature} & \\textbf{NumPy (\\texttt{numpy.linalg})} & \\textbf{SciPy (\\texttt{scipy.linalg})} \\\\\n",
    "\\hline\n",
    "Basic Linear Algebra & ✅ Yes & ✅ Yes \\\\\n",
    "\\hline\n",
    "Advanced Decompositions & ❌ No & ✅ Yes (LU, QR, etc.) \\\\\n",
    "\\hline\n",
    "Sparse Matrix Support & ❌ No & ✅ Yes (\\texttt{scipy.sparse.linalg}) \\\\\n",
    "\\hline\n",
    "Optimized Performance & Moderate & Better (for large systems) \\\\\n",
    "\\hline\n",
    "\\end{tabular}\n",
    "\\end{center}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative solution techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
